{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch\n",
    "\n",
    "`Batch` is the internal data structure extensively used in Tianshou. It is designed to store and manipulate hierarchical named tensors. This tutorial aims to help users correctly understand the concept and the behavior of `Batch` so that users can make the best of Tianshou.\n",
    "\n",
    "The tutorial has three parts. We first explain the concept of hierarchical named tensors, and introduce basic usage of `Batch`, followed by advanced topics of `Batch`.\n",
    "\n",
    "## Hierarchical Named Tensors\n",
    "\n",
    "\"Hierarchical named tensors\" refers to a set of tensors where their names form a hierarchy. Suppose there are four tensors `[t1, t2, t3, t4]` with names `[name1, name2, name3, name4]`, where `name1` and `name2` belong to the same namespace `name0`, then the full name of tensor `t1` is `name0.name1`. That is, the hierarchy lies in the names of tensors.\n",
    "\n",
    "We can describe the structure of hierarchical named tensors using a tree. There is always a \"virtual root\" node to represent the whole object; internal nodes are keys (names), and leaf nodes are values (scalars or tensors).\n",
    "\n",
    "Hierarchical named tensors are needed because we have to deal with the heterogeneity of reinforcement learning problems. The abstraction of RL is very simple:\n",
    "\n",
    "```python\n",
    "state, reward, done = env.step(action)\n",
    "```\n",
    "\n",
    "`reward` and `done` are simple, they are mostly scalar values. However, the `state` and `action` vary with environments. For example, `state` can be simply a vector, a tensor, or a camera input combined with sensory input. In the last case, it is natural to store them as hierarchical named tensors. This hierarchy can go beyond `state` and `action`: we can store `state`, `action`, `reward`, and `done` together as hierarchical named tensors.\n",
    "\n",
    "Note that, storing hierarchical named tensors is as easy as creating nested dictionary objects:\n",
    "\n",
    "```python\n",
    "{\n",
    "    'done': done,\n",
    "    'reward': reward,\n",
    "    'state': {\n",
    "        'camera': camera,\n",
    "        'sensory': sensory\n",
    "    },\n",
    "    'action': {\n",
    "        'direct': direct,\n",
    "        'point_3d': point_3d,\n",
    "        'force': force,\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "The real problem is how to **manipulate them**, such as adding new transition tuples into replay buffer and dealing with their heterogeneity. `Batch` is designed to easily create, store, and manipulate these hierarchical named tensors.\n",
    "\n",
    "Think of Batch as a numpy-enhanced version of a Python dictionary. It is also similar to PyTorch's tensordict, although with a somewhat different type structure.\n",
    "\n",
    "<div align=center>\n",
    "<img src=\"https://tianshou.readthedocs.io/en/master/_images/concepts_arch.png\", title=\"The data flow is converted into a Batch in Tianshou\">\n",
    "\n",
    "<a> Data flow is converted into a Batch in Tianshou </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:11:59.939372Z",
     "start_time": "2025-10-24T15:11:59.932800Z"
    },
    "tags": [
     "remove-output",
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from tianshou.data import Batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Usage\n",
    "\n",
    "Here we cover some basic usages of `Batch`, describing what `Batch` contains, how to construct `Batch` objects and how to manipulate them.\n",
    "\n",
    "### What Does Batch Contain\n",
    "\n",
    "The content of `Batch` objects can be defined by the following rules:\n",
    "\n",
    "1. A `Batch` object can be an empty `Batch()`, or have at least one key-value pair. `Batch()` can be used to reserve keys, too. See the Advanced Topics section for this usage.\n",
    "\n",
    "2. The keys are always strings (they are names of corresponding values).\n",
    "\n",
    "3. The values can be scalars, tensors, or Batch objects. The recursive definition makes it possible to form a hierarchy of batches.\n",
    "\n",
    "4. Tensors are the most important values. In short, tensors are n-dimensional arrays of the same data type. We support two types of tensors: [PyTorch](https://pytorch.org/) tensor type `torch.Tensor` and [NumPy](https://numpy.org/) tensor type `np.ndarray`.\n",
    "\n",
    "5. Scalars are also valid values. A scalar is a single boolean, number, or object. They can be Python scalar (`False`, `1`, `2.3`, `None`, `'hello'`) or NumPy scalar (`np.bool_(True)`, `np.int32(1)`, `np.float64(2.3)`). They just shouldn't be mixed up with Batch/dict/tensors.\n",
    "\n",
    "**Note:** `Batch` cannot store `dict` objects, because internally `Batch` uses `dict` to store data. During construction, `dict` objects will be automatically converted to `Batch` objects.\n",
    "\n",
    "The data types of tensors are bool and numbers (any size of int and float as long as they are supported by NumPy or PyTorch). Besides, NumPy supports ndarray of objects and we take advantage of this feature to store non-number objects in `Batch`. If one wants to store data that are neither boolean nor numbers (such as strings and sets), they can store the data in `np.ndarray` with the `np.object` data type. This way, `Batch` can store any type of Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:11:59.975455Z",
     "start_time": "2025-10-24T15:11:59.963893Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array(4),\n",
      "    b: array([5, 5]),\n",
      "    c: '2312312',\n",
      "    d: array(['a', '-2', '-3'], dtype=object),\n",
      ")\n",
      "[5 5]\n"
     ]
    }
   ],
   "source": [
    "data = Batch(a=4, b=[5, 5], c=\"2312312\", d=(\"a\", -2, -3))\n",
    "print(data)\n",
    "print(data.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A batch stores all passed in data as key-value pairs, and automatically turns the value into a numpy array if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of Batch\n",
    "\n",
    "There are two ways to construct a `Batch` object: from a `dict`, or using `kwargs`. Below are some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Batch from dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.031118Z",
     "start_time": "2025-10-24T15:12:00.022600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5]\n",
      "Batch(\n",
      "    a: array(4),\n",
      "    b: array([3, 4, 5]),\n",
      "    c: '2312312',\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Directly passing a dict object (possibly nested) is ok\n",
    "data = Batch({\"a\": 4, \"b\": [5, 5], \"c\": \"2312312\"})\n",
    "# The list will automatically be converted to numpy array\n",
    "print(data.b)\n",
    "data.b = np.array([3, 4, 5])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.085672Z",
     "start_time": "2025-10-24T15:12:00.078672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([0., 1.]),\n",
      "    b: array(['hello', 'world'], dtype=object),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# A list of dict objects (possibly nested) will be automatically stacked\n",
    "data = Batch([{\"a\": 0.0, \"b\": \"hello\"}, {\"a\": 1.0, \"b\": \"world\"}])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construct Batch from kwargs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.167872Z",
     "start_time": "2025-10-24T15:12:00.161872Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      "    c: array([None, None], dtype=object),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Construct a Batch with keyword arguments\n",
    "data = Batch(a=[4, 4], b=[5, 5], c=[None, None])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.385728Z",
     "start_time": "2025-10-24T15:12:00.377729Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      "    c: array([None, None], dtype=object),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Combining keyword arguments and batch_dict works fine\n",
    "data = Batch(\n",
    "    {\"a\": [4, 4], \"b\": [5, 5]}, c=[None, None]\n",
    ")  # the first argument is a dict, and 'c' is a keyword argument\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.450327Z",
     "start_time": "2025-10-24T15:12:00.443325Z"
    }
   },
   "outputs": [],
   "source": [
    "arr = np.zeros((3, 4))\n",
    "# By default, Batch only keeps the reference to the data, but it also supports data copying\n",
    "data = Batch(arr=arr, copy=True)  # data.arr now is a copy of 'arr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nested Batch construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.496467Z",
     "start_time": "2025-10-24T15:12:00.486951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    action: array([1., 2., 3.]),\n",
      "    reward: array(3.66),\n",
      "    obs: Batch(\n",
      "             rgb_obs: array([[0., 0., 0.],\n",
      "                             [0., 0., 0.],\n",
      "                             [0., 0., 0.]]),\n",
      "             flatten_obs: array([1., 1., 1., 1., 1.]),\n",
      "         ),\n",
      "    extra: 'extra_string',\n",
      ")\n",
      "<class 'tianshou.data.batch.Batch'>\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# The dictionary can be nested, and it will be turned into a nested Batch\n",
    "data = {\n",
    "    \"action\": np.array([1.0, 2.0, 3.0]),\n",
    "    \"reward\": 3.66,\n",
    "    \"obs\": {\n",
    "        \"rgb_obs\": np.zeros((3, 3)),\n",
    "        \"flatten_obs\": np.ones(5),\n",
    "    },\n",
    "}\n",
    "\n",
    "batch = Batch(data, extra=\"extra_string\")\n",
    "print(batch)\n",
    "# batch.obs is also a Batch\n",
    "print(type(batch.obs))\n",
    "print(batch.obs.rgb_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.555438Z",
     "start_time": "2025-10-24T15:12:00.547439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    action: array([[1., 2., 3.],\n",
      "                   [1., 2., 3.],\n",
      "                   [1., 2., 3.]]),\n",
      "    reward: array([3.66, 3.66, 3.66]),\n",
      "    obs: Batch(\n",
      "             flatten_obs: array([[1., 1., 1., 1., 1.],\n",
      "                                 [1., 1., 1., 1., 1.],\n",
      "                                 [1., 1., 1., 1., 1.]]),\n",
      "             rgb_obs: array([[[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]],\n",
      "                      \n",
      "                             [[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]],\n",
      "                      \n",
      "                             [[0., 0., 0.],\n",
      "                              [0., 0., 0.],\n",
      "                              [0., 0., 0.]]]),\n",
      "         ),\n",
      ")\n",
      "(3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "# A list of dictionary/Batch will automatically be concatenated/stacked, providing convenience if you\n",
    "# want to use parallelized environments to collect data.\n",
    "batch = Batch([data] * 3)\n",
    "print(batch)\n",
    "print(batch.obs.rgb_obs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation With Batch\n",
    "\n",
    "Users can access the internal data by `b.key` or `b[key]`, where `b.key` finds the sub-tree with `key` as the root node. If the result is a sub-tree with non-empty keys, the key-reference can be chained, i.e. `b.key.key1.key2.key3`. When it reaches a leaf node, users get the data (scalars/tensors) stored in that `Batch` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.615890Z",
     "start_time": "2025-10-24T15:12:00.607372Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 5]\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "data = Batch(a=4, b=[5, 5])\n",
    "print(data.b)\n",
    "# obj.key is equivalent to obj[\"key\"]\n",
    "print(data[\"a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.680567Z",
     "start_time": "2025-10-24T15:12:00.668485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a: 4\n",
      "b: [5 5]\n"
     ]
    }
   ],
   "source": [
    "# Iterating over data items like a dict is supported\n",
    "for key, value in data.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.738727Z",
     "start_time": "2025-10-24T15:12:00.732208Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "# obj.keys() and obj.values() work just like dict.keys() and dict.values()\n",
    "for key in data.keys():\n",
    "    print(f\"{key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.799183Z",
     "start_time": "2025-10-24T15:12:00.793003Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array(4),\n",
      "    b: array([5, 5]),\n",
      "    c: array(1),\n",
      "    d: array(2),\n",
      "    e: array(3),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# obj.update() behaves like dict.update()\n",
    "# this is the same as data.c = 1; data.d = 2; data.e = 3;\n",
    "data.update(c=1, d=2, e=3)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:00.963920Z",
     "start_time": "2025-10-24T15:12:00.943883Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([4, 4]),\n",
      "    b: array([5, 5]),\n",
      ")\n",
      "Batch(\n",
      "    b: array([5, 5]),\n",
      "    c: Batch(\n",
      "           c1: array([0, 1, 2]),\n",
      "           c2: array(False),\n",
      "       ),\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Add or delete key-value pair in batch\n",
    "batch1 = Batch({\"a\": [4, 4], \"b\": (5, 5)})\n",
    "print(batch1)\n",
    "\n",
    "batch1.c = Batch(c1=np.arange(3), c2=False)\n",
    "del batch1.a\n",
    "print(batch1)\n",
    "\n",
    "# Access value by key\n",
    "assert batch1[\"c\"] is batch1.c\n",
    "print(\"c\" in batch1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If `data` is a `dict` object, `for x in data` iterates over keys in the dict. However, it has a different meaning for `Batch` objects: `for x in data` iterates over `data[0], data[1], ..., data[-1]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length, Shape, Indexing, and Slicing of Batch\n",
    "\n",
    "`Batch` also partially reproduces the NumPy ndarray APIs. It supports advanced slicing, such as `batch[:, i]` so long as the slice is valid. Broadcast mechanism of NumPy works for `Batch`, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.070169Z",
     "start_time": "2025-10-24T15:12:01.049650Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "[2, 2]\n"
     ]
    }
   ],
   "source": [
    "# Initialize Batch with tensors\n",
    "data = Batch(a=np.array([[0.0, 2.0], [1.0, 3.0]]), b=[[5.0, -5.0], [1.0, -2.0]])\n",
    "# If values have the same length/shape, that length/shape is used for this Batch\n",
    "print(len(data))\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.184740Z",
     "start_time": "2025-10-24T15:12:01.178737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([0., 2.]),\n",
      "    b: array([ 5., -5.]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Access the first item of all the stored tensors, while keeping the structure of Batch\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.264494Z",
     "start_time": "2025-10-24T15:12:01.246493Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 2.]\n",
      "[1. 3.]\n"
     ]
    }
   ],
   "source": [
    "# Iterates over data[0], data[1], ..., data[-1]\n",
    "for sample in data:\n",
    "    print(sample.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.334651Z",
     "start_time": "2025-10-24T15:12:01.328652Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([[0., 3.],\n",
      "              [1., 4.]]),\n",
      "    b: array([[ 5., -4.],\n",
      "              [ 1., -1.]]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Advanced slicing works just fine\n",
    "# Arithmetic operations are passed to each value in the Batch, with broadcast enabled\n",
    "data[:, 1] += 1\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.604151Z",
     "start_time": "2025-10-24T15:12:01.595633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array(2.),\n",
      "    b: array(0.25),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Amazingly, you can directly apply np.mean to a Batch object\n",
    "print(np.mean(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.741294Z",
     "start_time": "2025-10-24T15:12:01.732304Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Batch(\n",
       "     a: array([0., 3.]),\n",
       "     b: array([ 5., -4.]),\n",
       " ),\n",
       " Batch(\n",
       "     a: array([1., 4.]),\n",
       "     b: array([ 1., -1.]),\n",
       " )]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Directly converted to a list is also available\n",
    "list(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example with environment stepping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.832003Z",
     "start_time": "2025-10-24T15:12:01.822001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    terminated: array([False, False, False, False]),\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    truncated: array([False, False, False, False]),\n",
      "    rew: array([0., 0., 0., 0.]),\n",
      "    info: Batch(\n",
      "              done: array([1, 1, 0, 1]),\n",
      "              failed: array([False, False, False, False]),\n",
      "          ),\n",
      "    act: array([9, 1, 6, 6]),\n",
      ")\n",
      "[4]\n"
     ]
    }
   ],
   "source": [
    "# Let us suppose we have collected the data from stepping from 4 environments\n",
    "step_outputs = [\n",
    "    {\n",
    "        \"act\": np.random.randint(10),\n",
    "        \"rew\": 0.0,\n",
    "        \"obs\": np.ones((3, 3)),\n",
    "        \"info\": {\"done\": np.random.choice(2), \"failed\": False},\n",
    "        \"terminated\": False,\n",
    "        \"truncated\": False,\n",
    "    }\n",
    "    for _ in range(4)\n",
    "]\n",
    "batch = Batch(step_outputs)\n",
    "print(batch)\n",
    "print(batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:01.955648Z",
     "start_time": "2025-10-24T15:12:01.944997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    terminated: False,\n",
      "    obs: array([[1., 1., 1.],\n",
      "                [1., 1., 1.],\n",
      "                [1., 1., 1.]]),\n",
      "    truncated: False,\n",
      "    rew: 0.0,\n",
      "    info: Batch(\n",
      "              done: 1,\n",
      "              failed: False,\n",
      "          ),\n",
      "    act: 9,\n",
      ")\n",
      "Batch(\n",
      "    terminated: array([False, False]),\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    truncated: array([False, False]),\n",
      "    rew: array([0., 0.]),\n",
      "    info: Batch(\n",
      "              done: array([1, 1]),\n",
      "              failed: array([False, False]),\n",
      "          ),\n",
      "    act: array([9, 6]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Advanced indexing is supported, if we only want to select data in a given set of environments\n",
    "print(batch[0])\n",
    "print(batch[[0, 3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.108030Z",
     "start_time": "2025-10-24T15:12:02.100001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    terminated: array([False, False]),\n",
      "    obs: array([[[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]],\n",
      "         \n",
      "                [[1., 1., 1.],\n",
      "                 [1., 1., 1.],\n",
      "                 [1., 1., 1.]]]),\n",
      "    truncated: array([False, False]),\n",
      "    rew: array([0., 0.]),\n",
      "    info: Batch(\n",
      "              done: array([0, 1]),\n",
      "              failed: array([False, False]),\n",
      "          ),\n",
      "    act: array([6, 6]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Slicing is also supported\n",
    "print(batch[-2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack / Concatenate / Split of Batches\n",
    "\n",
    "Stacking and concatenating multiple `Batch` instances, or splitting an instance into multiple batches, are all easy and intuitive in Tianshou. For now, we stick to the aggregation (stack/concatenate) of homogeneous (same structure) batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.226183Z",
     "start_time": "2025-10-24T15:12:02.218107Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([[0., 2.],\n",
      "              [1., 3.]]),\n",
      "    b: array([ 5, -5]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_1 = Batch(a=np.array([0.0, 2.0]), b=5)\n",
    "data_2 = Batch(a=np.array([1.0, 3.0]), b=-5)\n",
    "data = Batch.stack((data_1, data_2))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.296801Z",
     "start_time": "2025-10-24T15:12:02.289288Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch(\n",
      "    a: array([[0., 2.]]),\n",
      "    b: array([5]),\n",
      "), Batch(\n",
      "    a: array([[1., 3.]]),\n",
      "    b: array([-5]),\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Split supports random shuffling\n",
    "data_split = list(data.split(1, shuffle=False))\n",
    "print(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.380363Z",
     "start_time": "2025-10-24T15:12:02.370362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([[0., 2.],\n",
      "              [1., 3.]]),\n",
      "    b: array([ 5, -5]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data_cat = Batch.cat(data_split)\n",
    "print(data_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More concatenation and stacking examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.434035Z",
     "start_time": "2025-10-24T15:12:02.420433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([3.]),\n",
      "              ),\n",
      "           b: array([1.]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([6.]),\n",
      "              ),\n",
      "           b: array([4.]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: Batch(\n",
      "           d: Batch(\n",
      "                  e: array([3., 6.]),\n",
      "              ),\n",
      "           b: array([1., 4.]),\n",
      "       ),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Concat batches with compatible keys\n",
    "b1 = Batch(a=[{\"b\": np.float64(1.0), \"d\": Batch(e=np.array(3.0))}])\n",
    "b2 = Batch(a=[{\"b\": np.float64(4.0), \"d\": {\"e\": np.array(6.0)}}])\n",
    "b12_cat_out = Batch.cat([b1, b2])\n",
    "print(b1)\n",
    "print(b2)\n",
    "print(b12_cat_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.496253Z",
     "start_time": "2025-10-24T15:12:02.483252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([[0., 0.],\n",
      "              [0., 0.],\n",
      "              [0., 0.]]),\n",
      "    b: array([[1., 1., 1.],\n",
      "              [1., 1., 1.]]),\n",
      "    c: Batch(\n",
      "           d: array([[1],\n",
      "                     [2]]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    a: array([[1., 1.],\n",
      "              [1., 1.],\n",
      "              [1., 1.]]),\n",
      "    b: array([[1., 1., 1.],\n",
      "              [1., 1., 1.]]),\n",
      "    c: Batch(\n",
      "           d: array([[0],\n",
      "                     [3]]),\n",
      "       ),\n",
      ")\n",
      "Batch(\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]],\n",
      "       \n",
      "              [[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]],\n",
      "       \n",
      "              [[0., 0.],\n",
      "               [1., 1.]],\n",
      "       \n",
      "              [[0., 0.],\n",
      "               [1., 1.]]]),\n",
      "    c: Batch(\n",
      "           d: array([[[1],\n",
      "                      [0]],\n",
      "              \n",
      "                     [[2],\n",
      "                      [3]]]),\n",
      "       ),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Stack batches with compatible keys\n",
    "b3 = Batch(a=np.zeros((3, 2)), b=np.ones((2, 3)), c=Batch(d=[[1], [2]]))\n",
    "b4 = Batch(a=np.ones((3, 2)), b=np.ones((2, 3)), c=Batch(d=[[0], [3]]))\n",
    "b34_stack = Batch.stack((b3, b4), axis=1)\n",
    "print(b3)\n",
    "print(b4)\n",
    "print(b34_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.558390Z",
     "start_time": "2025-10-24T15:12:02.550390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "[Batch(\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]]]),\n",
      "    c: Batch(\n",
      "           d: array([[[2],\n",
      "                      [3]]]),\n",
      "       ),\n",
      "), Batch(\n",
      "    b: array([[[1., 1., 1.],\n",
      "               [1., 1., 1.]]]),\n",
      "    a: array([[[0., 0.],\n",
      "               [1., 1.]]]),\n",
      "    c: Batch(\n",
      "           d: array([[[1],\n",
      "                      [0]]]),\n",
      "       ),\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "# Split the batch into small batches of size 1, breaking the order of the data\n",
    "print(type(b34_stack.split(1)))\n",
    "print(list(b34_stack.split(1, shuffle=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Type Converting\n",
    "\n",
    "Besides numpy array, Batch also supports PyTorch Tensor. The usages are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.644375Z",
     "start_time": "2025-10-24T15:12:02.632857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([0, 1, 0, 1, 0, 1]),\n",
      "    b: tensor([[0., 0.],\n",
      "               [0., 0.],\n",
      "               [1., 1.],\n",
      "               [1., 1.],\n",
      "               [0., 0.],\n",
      "               [0., 0.]]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch1 = Batch(a=np.arange(2), b=torch.zeros((2, 2)))\n",
    "batch2 = Batch(a=np.arange(2), b=torch.ones((2, 2)))\n",
    "batch_cat = Batch.cat([batch1, batch2, batch1])\n",
    "print(batch_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can convert the data type easily, if you no longer want to use hybrid data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.787129Z",
     "start_time": "2025-10-24T15:12:02.779128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]], dtype=torch.float64)\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "data = Batch(a=np.zeros((3, 4)))\n",
    "data.to_torch_(dtype=torch.float32, device=\"cpu\")\n",
    "print(data.a)\n",
    "# data.to_numpy_ is also available\n",
    "data.to_numpy_()\n",
    "print(data.a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.909153Z",
     "start_time": "2025-10-24T15:12:02.898633Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([0, 1, 0, 1, 0, 1]),\n",
      "    b: array([[0., 0.],\n",
      "              [0., 0.],\n",
      "              [1., 1.],\n",
      "              [1., 1.],\n",
      "              [0., 0.],\n",
      "              [0., 0.]], dtype=float32),\n",
      ")\n",
      "Batch(\n",
      "    a: tensor([0, 1, 0, 1, 0, 1], dtype=torch.int32),\n",
      "    b: tensor([[0., 0.],\n",
      "               [0., 0.],\n",
      "               [1., 1.],\n",
      "               [1., 1.],\n",
      "               [0., 0.],\n",
      "               [0., 0.]]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch_cat.to_numpy_()\n",
    "print(batch_cat)\n",
    "batch_cat.to_torch_()\n",
    "print(batch_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialization\n",
    "\n",
    "Batch is serializable and therefore Pickle compatible. `Batch` objects can be saved to disk and later restored by the Python `pickle` module. This pickle compatibility is especially important for distributed sampling from environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:02.993402Z",
     "start_time": "2025-10-24T15:12:02.983402Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    obs: Batch(\n",
      "             a: array(0.),\n",
      "             c: tensor([1., 2.]),\n",
      "         ),\n",
      "    np: array([[0., 0., 0., 0.],\n",
      "               [0., 0., 0., 0.],\n",
      "               [0., 0., 0., 0.]]),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "batch = Batch(obs=Batch(a=0.0, c=torch.Tensor([1.0, 2.0])), np=np.zeros([3, 4]))\n",
    "batch_pk = pickle.loads(pickle.dumps(batch))\n",
    "print(batch_pk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Topics\n",
    "\n",
    "From here on, this tutorial focuses on advanced topics of `Batch`, including key reservation, length/shape, and aggregation of heterogeneous batches.\n",
    "\n",
    "### Key Reservations\n",
    "\n",
    "In many cases, we know in the first place what keys we have, but we do not know the shape of values until we run the environment. To deal with this, Tianshou supports key reservations: **reserve a key and use a placeholder value**.\n",
    "\n",
    "The usage is easy: just use `Batch()` to be the value of reserved keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.051584Z",
     "start_time": "2025-10-24T15:12:03.041584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    b: Batch(),\n",
      ")\n",
      "Batch(\n",
      "    b: Batch(\n",
      "           c: Batch(),\n",
      "       ),\n",
      "    d: Batch(),\n",
      ")\n",
      "Batch(\n",
      "    key1: array([1, 2]),\n",
      "    key2: array([3, 4]),\n",
      "    key3: Batch(\n",
      "              key4: Batch(),\n",
      "              key5: Batch(),\n",
      "          ),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "a = Batch(b=Batch())  # 'b' is a reserved key\n",
    "print(a)\n",
    "\n",
    "# This is called hierarchical key reservation\n",
    "a = Batch(b=Batch(c=Batch()), d=Batch())  # 'c' and 'd' are reserved keys\n",
    "print(a)\n",
    "\n",
    "a = Batch(key1=np.array([1, 2]), key2=np.array([3, 4]), key3=Batch(key4=Batch(), key5=Batch()))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, we can use a tree to show the structure of `Batch` objects with reserved keys, where reserved keys are special internal nodes that do not have attached leaf nodes.\n",
    "\n",
    "**Note:** Reserved keys mean that in the future there will eventually be values attached to them. The values can be scalars, tensors, or even **Batch** objects. Understanding this is critical to understanding the behavior of `Batch` when dealing with heterogeneous Batches.\n",
    "\n",
    "The introduction of reserved keys gives rise to the need to check if a key is reserved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.121366Z",
     "start_time": "2025-10-24T15:12:03.111840Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Examples of checking whether Batch is empty\n",
    "print(len(Batch().get_keys()) == 0)\n",
    "print(len(Batch(a=Batch(), b=Batch(c=Batch())).get_keys()) == 0)\n",
    "print(len(Batch(a=Batch(), b=Batch(c=Batch()))) == 0)\n",
    "print(len(Batch(d=1).get_keys()) == 0)\n",
    "print(len(Batch(a=np.float64(1.0)).get_keys()) == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check whether a Batch is empty, simply use `len(Batch.get_keys()) == 0` to decide whether to identify direct emptiness (just a `Batch()`) or `len(Batch) == 0` to identify recursive emptiness (a `Batch` object without any scalar/tensor leaf nodes).\n",
    "\n",
    "**Note:** Do not get confused with `Batch.empty`. `Batch.empty` and its in-place variant `Batch.empty_` are used to set some values to zeros or None. Check the API documentation for further details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length and Shape Details\n",
    "\n",
    "The most common usage of `Batch` is to store a batch of data. The term \"Batch\" comes from the deep learning community to denote a mini-batch of sampled data from the whole dataset. In this regard, \"Batch\" typically means a collection of tensors whose first dimensions are the same. Then the length of a `Batch` object is simply the batch-size.\n",
    "\n",
    "If all the leaf nodes in a `Batch` object are tensors, but they have different lengths, they can be readily stored in `Batch`. However, for `Batch` of this kind, the `len(obj)` seems a bit ambiguous. Currently, Tianshou returns the length of the shortest tensor, but we strongly recommend that users do not use the `len(obj)` operator on `Batch` objects with tensors of different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.173748Z",
     "start_time": "2025-10-24T15:12:03.164747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "2\n",
      "[]\n",
      "TypeError: Entry for a in Batch(\n",
      "    a: 5.0,\n",
      "    b: array([[0., 0., 0., 0.],\n",
      "              [0., 0., 0., 0.],\n",
      "              [0., 0., 0., 0.]]),\n",
      ") is 5.0 has no len()\n"
     ]
    }
   ],
   "source": [
    "# Examples of len and obj.shape for Batch objects\n",
    "data = Batch(a=[5.0, 4.0], b=np.zeros((2, 3, 4)))\n",
    "print(data.shape)\n",
    "print(len(data))\n",
    "print(data[0].shape)\n",
    "try:\n",
    "    len(data[0])\n",
    "except TypeError as e:\n",
    "    print(f\"TypeError: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Following the convention of scientific computation, scalars have no length. If there is any scalar leaf node in a `Batch` object, an exception will occur when users call `len(obj)`.\n",
    "\n",
    "Besides, values of reserved keys are undetermined, so they have no length, neither. Or, to be specific, values of reserved keys have lengths of **any**. When there is a mix of tensors and reserved keys, the latter will be ignored in `len(obj)` and the minimum length of tensors is returned. When there is not any tensor in the `Batch` object, Tianshou raises an exception, too.\n",
    "\n",
    "The `obj.shape` attribute of `Batch` behaves somewhat similar to `len(obj)`:\n",
    "\n",
    "1. If all the leaf nodes in a `Batch` object are tensors with the same shape, that shape is returned.\n",
    "\n",
    "2. If all the leaf nodes in a `Batch` object are tensors but they have different shapes, the minimum length of each dimension is returned.\n",
    "\n",
    "3. If there is any scalar value in a `Batch` object, `obj.shape` returns `[]`.\n",
    "\n",
    "4. The shape of reserved keys is undetermined, too. We treat their shape as `[]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregation of Heterogeneous Batches\n",
    "\n",
    "In this section, we talk about aggregation operators (stack/concatenate) on heterogeneous `Batch` objects. We only consider the heterogeneity in the structure of `Batch` objects. The aggregation operators are eventually done by NumPy/PyTorch operators (`np.stack`, `np.concatenate`, `torch.stack`, `torch.cat`). Heterogeneity in values can fail these operators (such as stacking `np.ndarray` with `torch.Tensor`, or stacking tensors with different shapes) and an exception will be raised.\n",
    "\n",
    "The behavior is natural: for keys that are not shared across all batches, batches that do not have these keys will be padded by zeros (or `None` if the data type is `np.object`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.235449Z",
     "start_time": "2025-10-24T15:12:03.225930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 4, 4)\n",
      "(2, 4, 6)\n",
      "(2, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "# Examples of stack: a is missing key `b`, and b is missing key `a`\n",
    "a = Batch(a=np.zeros([4, 4]), common=Batch(c=np.zeros([4, 5])))\n",
    "b = Batch(b=np.zeros([4, 6]), common=Batch(c=np.zeros([4, 5])))\n",
    "c = Batch.stack([a, b])\n",
    "print(c.a.shape)\n",
    "print(c.b.shape)\n",
    "print(c.common.c.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.277541Z",
     "start_time": "2025-10-24T15:12:03.269485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(\n",
      "    a: array([[0., 2.],\n",
      "              [1., 3.]]),\n",
      "    b: array([None, 'done'], dtype=object),\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# None or 0 is padded with appropriate shape\n",
    "data_1 = Batch(a=np.array([0.0, 2.0]))\n",
    "data_2 = Batch(a=np.array([1.0, 3.0]), b=\"done\")\n",
    "data = Batch.stack((data_1, data_2))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.315794Z",
     "start_time": "2025-10-24T15:12:03.308277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Examples of cat: a is missing key `b`, and b is missing key `a`\n",
    "a = Batch(a=np.zeros([3, 4]), common=Batch(c=np.zeros([3, 5])))\n",
    "b = Batch(b=np.zeros([4, 3]), common=Batch(c=np.zeros([4, 5])))\n",
    "# TODO: Something has changed; this is actually no longer admissible!\n",
    "# c = Batch.cat([a, b])\n",
    "# print(c.a.shape)\n",
    "# print(c.b.shape)\n",
    "# print(c.common.c.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are some cases when batches are too heterogeneous that they cannot be aggregated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-24T15:12:03.386127Z",
     "start_time": "2025-10-24T15:12:03.378127Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Users\\Dominik Jain\\Dev\\AI\\tianshou\\tianshou\\data\\batch.py:1084: UserWarning: You are using tensors with different shape, fallback to dtype=object by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# This will raise an exception\n",
    "try:\n",
    "    a = Batch(a=np.zeros([4, 4]))\n",
    "    b = Batch(a=Batch(b=Batch()))\n",
    "    c = Batch.stack([a, b])\n",
    "except Exception as e:\n",
    "    print(f\"Exception: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then how to determine if batches can be aggregated? Let's rethink the purpose of reserved keys. What is the advantage of `a1=Batch(b=Batch())` over `a2=Batch()`? The only difference is that `a1.b` returns `Batch()` but `a2.b` raises an exception. That's to say, **we reserve keys for attribute reference**.\n",
    "\n",
    "We say a key chain `k=[key1, key2, ..., keyn]` applies to `b` if the expression `b.key1.key2.{...}.keyn` is valid, and the result is `b[k]`.\n",
    "\n",
    "For a set of `Batch` objects denoted as S, they can be aggregated if there exists a `Batch` object `b` satisfying the following rules:\n",
    "\n",
    "1. **Key chain applicability:** For any object `bi` in S, and any key chain `k`, if `bi[k]` is valid, then `b[k]` is valid.\n",
    "\n",
    "2. **Type consistency:** If `bi[k]` is not `Batch()` (the last key in the key chain is not a reserved key), then the type of `b[k]` should be the same as `bi[k]` (both should be scalar/tensor/non-empty Batch values).\n",
    "\n",
    "The `Batch` object `b` satisfying these rules with the minimum number of keys determines the structure of aggregating S. The values are relatively easy to define: for any key chain `k` that applies to `b`, `b[k]` is the stack/concatenation of `[bi[k] for bi in S]` (if `k` does not apply to `bi`, the appropriate size of zeros or `None` are filled automatically). If `bi[k]` are all `Batch()`, then the aggregation result is also an empty `Batch()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miscellaneous Notes\n",
    "\n",
    "1. It is often the case that the observations returned from the environment are all NumPy ndarray but the policy requires `torch.Tensor` for prediction and learning. In this regard, Tianshou provides helper functions to convert the stored data in-place into Numpy arrays or Torch tensors.\n",
    "\n",
    "2. `obj.stack_([a, b])` is the same as `Batch.stack([obj, a, b])`, and `obj.cat_([a, b])` is the same as `Batch.cat([obj, a, b])`. Considering the frequent requirement of concatenating two `Batch` objects, Tianshou also supports `obj.cat_(a)` to be an alias of `obj.cat_([a])`.\n",
    "\n",
    "3. `Batch.cat` and `Batch.cat_` does not support `axis` argument as `np.concatenate` and `torch.cat` currently.\n",
    "\n",
    "4. `Batch.stack` and `Batch.stack_` support the `axis` argument so that one can stack batches besides the first dimension. But be cautious, if there are keys that are not shared across all batches, `stack` with `axis != 0` is undefined, and will cause an exception currently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Reading\n",
    "\n",
    "Would you like to learn more advanced usages of Batch? Feel curious about how data is organized inside the Batch? Check the [documentation](https://tianshou.readthedocs.io/en/master/03_api/data/batch.html) for more details."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
